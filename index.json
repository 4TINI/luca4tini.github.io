
    
    
    
    
    
    [{"authors":null,"categories":null,"content":" I bla bla bla bla s\n","date":1692576000,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1692576000,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I bla bla bla bla s","tags":null,"title":"","type":"authors"},{"authors":[""],"categories":[],"content":"AB tests or randomized controlled trials are the gold standard in causal inference. By randomly exposing units to a treatment we make sure that individuals in both groups are comparable, on average, and any difference we observe can be attributed to the treatment effect alone.\nHowever, often the treatment and control groups are not perfectly comparable. This could be due to the fact that randomization was not perfect or available. Not always we can randomize a treatment, for ethical or practical reasons. And even when we can, sometimes we do not have enough individuals or units so that differences between groups are seizable. This happens often, for example, when randomization is not done at the individual level, but at a higher level of aggregation, for example zipcodes, counties or even states.\nIn these settings, we can still recover a causal estimate of the treatment effect if we have enough information about individuals, by making the treatment and control group comparable, ex-post. In this blog post, we are going to introduce and compare different procedures to estimate causal effects in presence of imbalances between treatment and control groups that are fully observable. In particular we are going to analyze weighting, matching and regression procedures.\nExample Assume we had blog on statistics and causal inference ðŸ˜‡. To improve user experience, we are considering releasing a dark mode, and we would like to understand whether this new feature increases the time users spend on our blog.\nWe are not a sophisticated company, therefore we do not run an AB test but we simply release the dark mode and we observe whether users select it or not and the time they spend on the blog. We know that there might be selection: users that prefer the dark mode could have different reading preferences and this might complicate our causal analysis.\nWe can represent the data generating process with the following Directed Acyclic Graph (DAG).\nflowchart TB classDef included fill:#DCDCDC,stroke:#000000,stroke-width:2px; classDef excluded fill:#ffffff,stroke:#000000,stroke-width:2px; classDef unobserved fill:#ffffff,stroke:#000000,stroke-width:2px,stroke-dasharray: 5 5; X1((gender)) X2((age)) X3((hours)) D((dark mode)) Y((read time)) D --\u0026gt; Y X1 --\u0026gt; Y X1 --\u0026gt; D X2 --\u0026gt; D X3 --\u0026gt; Y class D,Y included; class X1,X2,X3 excluded; We generate the simulated data using the data generating process dgp_darkmode() from src.dgp. I also import some plotting functions and libraries from src.utils.\n%matplotlib inline %config InlineBackend.figure_format = \u0026#39;retina\u0026#39; from src.utils import * from src.dgp import dgp_darkmode df = dgp_darkmode().generate_data() df.head() read_time dark_mode male age hours 0 14.4 False 0 43.0 65.6 1 15.4 False 1 55.0 125.4 2 20.9 True 0 23.0 642.6 3 20.0 False 0 41.0 129.1 4 21.5 True 0 29.0 190.2 We have informations on 300 users for whom we observe whether they select the dark_mode (the treatment), their weekly read_time (the outcome of interest) and some characteristics like gender, age and total hours previously spend on the blog.\nWe would like to estimate the effect of the new dark_mode on usersâ€™ read_time. If we were runnig an AB test or randomized control trial, we could just compare users with and without the dark mode and we could attribute the difference in average reading time to the dark_mode. Letâ€™s check what number we would get.\nnp.mean(df.loc[df.dark_mode==True, \u0026#39;read_time\u0026#39;]) - np.mean(df.loc[df.dark_mode==False, \u0026#39;read_time\u0026#39;]) -0.4446330948042103 Individuals that select the dark_mode spend on average 1.37 hours less on the blog, per week. Should we conclude that dark_mode is a bad idea? Is this a causal effect?\nWe did not randomize the dark_mode so that users that selected it might not be directly comparable with users that didnâ€™t. Can we verify this concern? Partially. We can only check characteristics that we observe, gender, age and total hours in our setting. We cannot check if users differ along other dimensions that we donâ€™t observe.\nLetâ€™s use the create_table_one function from Uberâ€™s causalml package to produce a covariate balance table, containing the average value of our observable characteristics, across treatment and control groups. As the name suggests, this should always be the first table you present in causal inference analysis.\nfrom causalml.match import create_table_one X = [\u0026#39;male\u0026#39;, \u0026#39;age\u0026#39;, \u0026#39;hours\u0026#39;] table1 = create_table_one(df, \u0026#39;dark_mode\u0026#39;, X) table1 Control Treatment SMD Variable n 151 149 age 46.01 (9.79) 39.09 (11.53) -0.6469 hours 337.78 (464.00) 328.57 (442.12) -0.0203 male 0.34 (0.47) 0.66 (0.48) 0.6732 There seems to be some difference between treatment (dark_mode) and control group. In particular, users that select the dark_mode are older, have spent less hours on the blog and they are more likely to be males.\nAnother way to visually observe all the differences at once is with a paired violinplot. The advantage of the paired violinplot is that it allows us to observe the full â€¦","date":1692576000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1692576000,"objectID":"087d3b6caff73927be00db27e434b85b","permalink":"https://4tini.github.io/luca4tini.github.io/post/weighting_matching-copy-2/","publishdate":"2023-08-21T00:00:00Z","relpermalink":"/luca4tini.github.io/post/weighting_matching-copy-2/","section":"post","summary":"Bla Bla Bla","tags":[],"title":"Weighting, Matching, or Regression?","type":"post"},{"authors":[""],"categories":[],"content":"AB tests or randomized controlled trials are the gold standard in causal inference. By randomly exposing units to a treatment we make sure that individuals in both groups are comparable, on average, and any difference we observe can be attributed to the treatment effect alone.\nHowever, often the treatment and control groups are not perfectly comparable. This could be due to the fact that randomization was not perfect or available. Not always we can randomize a treatment, for ethical or practical reasons. And even when we can, sometimes we do not have enough individuals or units so that differences between groups are seizable. This happens often, for example, when randomization is not done at the individual level, but at a higher level of aggregation, for example zipcodes, counties or even states.\nIn these settings, we can still recover a causal estimate of the treatment effect if we have enough information about individuals, by making the treatment and control group comparable, ex-post. In this blog post, we are going to introduce and compare different procedures to estimate causal effects in presence of imbalances between treatment and control groups that are fully observable. In particular we are going to analyze weighting, matching and regression procedures.\nExample Assume we had blog on statistics and causal inference ðŸ˜‡. To improve user experience, we are considering releasing a dark mode, and we would like to understand whether this new feature increases the time users spend on our blog.\nWe are not a sophisticated company, therefore we do not run an AB test but we simply release the dark mode and we observe whether users select it or not and the time they spend on the blog. We know that there might be selection: users that prefer the dark mode could have different reading preferences and this might complicate our causal analysis.\nWe can represent the data generating process with the following Directed Acyclic Graph (DAG).\nflowchart TB classDef included fill:#DCDCDC,stroke:#000000,stroke-width:2px; classDef excluded fill:#ffffff,stroke:#000000,stroke-width:2px; classDef unobserved fill:#ffffff,stroke:#000000,stroke-width:2px,stroke-dasharray: 5 5; X1((gender)) X2((age)) X3((hours)) D((dark mode)) Y((read time)) D --\u0026gt; Y X1 --\u0026gt; Y X1 --\u0026gt; D X2 --\u0026gt; D X3 --\u0026gt; Y class D,Y included; class X1,X2,X3 excluded; We generate the simulated data using the data generating process dgp_darkmode() from src.dgp. I also import some plotting functions and libraries from src.utils.\n%matplotlib inline %config InlineBackend.figure_format = \u0026#39;retina\u0026#39; from src.utils import * from src.dgp import dgp_darkmode df = dgp_darkmode().generate_data() df.head() read_time dark_mode male age hours 0 14.4 False 0 43.0 65.6 1 15.4 False 1 55.0 125.4 2 20.9 True 0 23.0 642.6 3 20.0 False 0 41.0 129.1 4 21.5 True 0 29.0 190.2 We have informations on 300 users for whom we observe whether they select the dark_mode (the treatment), their weekly read_time (the outcome of interest) and some characteristics like gender, age and total hours previously spend on the blog.\nWe would like to estimate the effect of the new dark_mode on usersâ€™ read_time. If we were runnig an AB test or randomized control trial, we could just compare users with and without the dark mode and we could attribute the difference in average reading time to the dark_mode. Letâ€™s check what number we would get.\nnp.mean(df.loc[df.dark_mode==True, \u0026#39;read_time\u0026#39;]) - np.mean(df.loc[df.dark_mode==False, \u0026#39;read_time\u0026#39;]) -0.4446330948042103 Individuals that select the dark_mode spend on average 1.37 hours less on the blog, per week. Should we conclude that dark_mode is a bad idea? Is this a causal effect?\nWe did not randomize the dark_mode so that users that selected it might not be directly comparable with users that didnâ€™t. Can we verify this concern? Partially. We can only check characteristics that we observe, gender, age and total hours in our setting. We cannot check if users differ along other dimensions that we donâ€™t observe.\nLetâ€™s use the create_table_one function from Uberâ€™s causalml package to produce a covariate balance table, containing the average value of our observable characteristics, across treatment and control groups. As the name suggests, this should always be the first table you present in causal inference analysis.\nfrom causalml.match import create_table_one X = [\u0026#39;male\u0026#39;, \u0026#39;age\u0026#39;, \u0026#39;hours\u0026#39;] table1 = create_table_one(df, \u0026#39;dark_mode\u0026#39;, X) table1 Control Treatment SMD Variable n 151 149 age 46.01 (9.79) 39.09 (11.53) -0.6469 hours 337.78 (464.00) 328.57 (442.12) -0.0203 male 0.34 (0.47) 0.66 (0.48) 0.6732 There seems to be some difference between treatment (dark_mode) and control group. In particular, users that select the dark_mode are older, have spent less hours on the blog and they are more likely to be males.\nAnother way to visually observe all the differences at once is with a paired violinplot. The advantage of the paired violinplot is that it allows us to observe the full â€¦","date":1692576000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1692576000,"objectID":"0be7a29ba132b98df094429f29566c39","permalink":"https://4tini.github.io/luca4tini.github.io/post/weighting_matching-copy/","publishdate":"2023-08-21T00:00:00Z","relpermalink":"/luca4tini.github.io/post/weighting_matching-copy/","section":"post","summary":"Bla Bla Bla","tags":[],"title":"Weighting, Matching, or Regression?","type":"post"},{"authors":[""],"categories":[],"content":"AB tests or randomized controlled trials are the gold standard in causal inference. By randomly exposing units to a treatment we make sure that individuals in both groups are comparable, on average, and any difference we observe can be attributed to the treatment effect alone.\nHowever, often the treatment and control groups are not perfectly comparable. This could be due to the fact that randomization was not perfect or available. Not always we can randomize a treatment, for ethical or practical reasons. And even when we can, sometimes we do not have enough individuals or units so that differences between groups are seizable. This happens often, for example, when randomization is not done at the individual level, but at a higher level of aggregation, for example zipcodes, counties or even states.\nIn these settings, we can still recover a causal estimate of the treatment effect if we have enough information about individuals, by making the treatment and control group comparable, ex-post. In this blog post, we are going to introduce and compare different procedures to estimate causal effects in presence of imbalances between treatment and control groups that are fully observable. In particular we are going to analyze weighting, matching and regression procedures.\nExample Assume we had blog on statistics and causal inference ðŸ˜‡. To improve user experience, we are considering releasing a dark mode, and we would like to understand whether this new feature increases the time users spend on our blog.\nWe are not a sophisticated company, therefore we do not run an AB test but we simply release the dark mode and we observe whether users select it or not and the time they spend on the blog. We know that there might be selection: users that prefer the dark mode could have different reading preferences and this might complicate our causal analysis.\nWe can represent the data generating process with the following Directed Acyclic Graph (DAG).\nflowchart TB classDef included fill:#DCDCDC,stroke:#000000,stroke-width:2px; classDef excluded fill:#ffffff,stroke:#000000,stroke-width:2px; classDef unobserved fill:#ffffff,stroke:#000000,stroke-width:2px,stroke-dasharray: 5 5; X1((gender)) X2((age)) X3((hours)) D((dark mode)) Y((read time)) D --\u0026gt; Y X1 --\u0026gt; Y X1 --\u0026gt; D X2 --\u0026gt; D X3 --\u0026gt; Y class D,Y included; class X1,X2,X3 excluded; We generate the simulated data using the data generating process dgp_darkmode() from src.dgp. I also import some plotting functions and libraries from src.utils.\n%matplotlib inline %config InlineBackend.figure_format = \u0026#39;retina\u0026#39; from src.utils import * from src.dgp import dgp_darkmode df = dgp_darkmode().generate_data() df.head() read_time dark_mode male age hours 0 14.4 False 0 43.0 65.6 1 15.4 False 1 55.0 125.4 2 20.9 True 0 23.0 642.6 3 20.0 False 0 41.0 129.1 4 21.5 True 0 29.0 190.2 We have informations on 300 users for whom we observe whether they select the dark_mode (the treatment), their weekly read_time (the outcome of interest) and some characteristics like gender, age and total hours previously spend on the blog.\nWe would like to estimate the effect of the new dark_mode on usersâ€™ read_time. If we were runnig an AB test or randomized control trial, we could just compare users with and without the dark mode and we could attribute the difference in average reading time to the dark_mode. Letâ€™s check what number we would get.\nnp.mean(df.loc[df.dark_mode==True, \u0026#39;read_time\u0026#39;]) - np.mean(df.loc[df.dark_mode==False, \u0026#39;read_time\u0026#39;]) -0.4446330948042103 Individuals that select the dark_mode spend on average 1.37 hours less on the blog, per week. Should we conclude that dark_mode is a bad idea? Is this a causal effect?\nWe did not randomize the dark_mode so that users that selected it might not be directly comparable with users that didnâ€™t. Can we verify this concern? Partially. We can only check characteristics that we observe, gender, age and total hours in our setting. We cannot check if users differ along other dimensions that we donâ€™t observe.\nLetâ€™s use the create_table_one function from Uberâ€™s causalml package to produce a covariate balance table, containing the average value of our observable characteristics, across treatment and control groups. As the name suggests, this should always be the first table you present in causal inference analysis.\nfrom causalml.match import create_table_one X = [\u0026#39;male\u0026#39;, \u0026#39;age\u0026#39;, \u0026#39;hours\u0026#39;] table1 = create_table_one(df, \u0026#39;dark_mode\u0026#39;, X) table1 Control Treatment SMD Variable n 151 149 age 46.01 (9.79) 39.09 (11.53) -0.6469 hours 337.78 (464.00) 328.57 (442.12) -0.0203 male 0.34 (0.47) 0.66 (0.48) 0.6732 There seems to be some difference between treatment (dark_mode) and control group. In particular, users that select the dark_mode are older, have spent less hours on the blog and they are more likely to be males.\nAnother way to visually observe all the differences at once is with a paired violinplot. The advantage of the paired violinplot is that it allows us to observe the full â€¦","date":1692576000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1692576000,"objectID":"ae435059a64a781cf23c8547c70087e0","permalink":"https://4tini.github.io/luca4tini.github.io/post/weighting_matching/","publishdate":"2023-08-21T00:00:00Z","relpermalink":"/luca4tini.github.io/post/weighting_matching/","section":"post","summary":"Bla Bla Bla","tags":[],"title":"Weighting, Matching, or Regression?","type":"post"},{"authors":null,"categories":null,"content":"The text and method is based on the following sources:\nYoutube, 2D Schrodinger Equation Numerical Solution in PYTHON, (2022), Available at: https://www.youtube.com/watch?v=DF1SnjXZcbM\u0026amp;list=WL\u0026amp;index=8 (Accessed: 6 March 2022). Alexvas, Discretization of Laplacian with boundary conditions, (2017), Available at: https://scicomp.stackexchange.com/q/25976 (Accessed: 6 March 2022). Thomas H. Pulliam, David W. Zingg., Fundamental Algorithms in Computational Fluid Dynamics, (2014), Springer, Available at: https://link.springer.com/book/10.1007/978-3-319-05053-9 (Accessed: 6 March 2022). using PyPlot, PyCall using LinearAlgebra using SparseArrays using Arpack, KrylovKit Two-dimensional box The goal is to solve the single particle SchrÃ¶dinger equation in a two-dimensional box of length $2L$ of the Hamiltonian: $$ \\hat{h}=\\frac{-\\hbar^{2}}{2 m} \\nabla^{2}+V(\\mathbf{r}, t). $$ The box can have a homogeneous Dirichlet boundary condition, i.e., the wave function evaluated at the border must vanish, or periodic boundary conditions. There can be a potential $V$ in the box. So let us a meshgrid of $\\mathbf{x}$ and $\\mathbf{y}$ coordinates.\nN = 100 L = 10.0 Î”xÂ² = (2*L/N)^2 function meshgrid(x::LinRange{Float64, Int64}, y::LinRange{Float64, Int64})::Tuple{Matrix{Float64}, Matrix{Float64}} X = [x for _ in y, x in x] Y = [y for y in y, _ in x] X, Y end x = LinRange(-L, L, N) y = LinRange(-L, L, N) X, Y = meshgrid(x, y); Potential The potential is chosen to be eightfold rotation symmetric quasicrystal, centered on $\\mathbf{r}=0,$ $$ V(\\mathbf{r})=V_{0} \\sum_{k=1}^{4} \\cos ^{2}\\left(\\mathbf{G}_{k} \\cdot \\mathbf{r}\\right) $$ where $V_{0}$ is the potential amplitude and the quantities $G_{k}$ are the lattice vectors of four mutually incoherent standing waves oriented at the angles $0^{\\circ}, 45^{\\circ}, 90^{\\circ}$, and $135^{\\circ}$, respectively. The lattice vectors have norm $\\left|G_{k}\\right|=\\pi / a$.\nfunction get_potential(x, y, Vâ‚€) return Vâ‚€*(cos(pi*x)^2 + cos(pi*âˆš2/2*(x+y))^2 + cos(pi*y)^2 + cos(-pi/(âˆš2)*(x-y))^2) end # def get_potential(x, y): # return np.exp(-(x-0.3)**2/(2*0.1**2))*np.exp(-(y-0.3)**2/(2*0.1**2)) V = get_potential.(X,Y, 0.005) fig = figure(figsize=(6.2,5)) contourf(X, Y, V, 50) # pcolormesh(X, Y, V, cmap=:RdBu) colorbar() # plot_surface(X, Y, V) PyObject \u0026lt;matplotlib.colorbar.Colorbar object at 0x0000000081FE1460\u0026gt; Units The SchrÃ¶dinger equation is given by $$ \\left[\\frac{-\\hbar^{2}}{2 m} \\nabla^{2}+V(\\mathbf{r})\\right] \\psi(\\mathbf{r}) = E\\psi(\\mathbf{r}),$$ Let us use the lattice spacing $a$ and the corresponding recoil energy $E_r = \\pi^2\\hbar^2/2ma^2$ as the space and energy units, respectively, such that we have $$ \\left[\\frac{-\\hbar^2}{2mE_ra^2} \\tilde{\\nabla}^{2}+\\frac{V(\\mathbf{\\tilde{r}})}{E_r}\\right] \\psi(\\mathbf{\\tilde{r}}) = \\left[\\frac{-1}{\\pi^2} \\tilde{\\nabla}^{2}+\\tilde{V}_{0} \\sum_{k=1}^{4} \\cos ^{2}\\left(\\tilde{\\mathbf{G}}_{k} \\cdot \\tilde{\\mathbf{r}}\\right)\\right] \\psi(\\mathbf{\\tilde{r}}) = \\tilde{E}\\psi(\\mathbf{\\tilde{r}}), $$ where $|\\tilde{\\mathbf{G}}_{k}|=\\pi$, $\\tilde{\\mathbf{r}} = \\frac{\\mathbf{r}}{a}$, and $\\tilde{E}=\\frac{E}{E_r}$.\nDiscretize in one dimension Rest us to discretize our Hamiltonian. The idea can be easily explained by the following finite difference approximation of the second derivative in one dimension $$ \\frac{d^2 \\psi}{dx^2} \\approx \\frac{\\psi_{i+1}-2\\psi_i + \\psi_{i-1}}{\\Delta x^2}.$$\nDirichlet boundary conditions Suppose we have $M=4$ interior points and $a$ and $b$ two boundary points, a mesh with four interior points $\\Delta x=2L /(M+1)$, represented as follows \\begin{align*} \u0026amp;\\qquad \\ \\ a \\ \\ \\ \\ 1 \\ \\ \\ \\ 2 \\ \\ \\ \\ 3 \\ \\ \\ \\, 4 \\ \\ \\ \\ b \\\\\\ \u0026amp;x=-L \\ - \\ - \\ - \\ - \\ \\ L \\end{align*} We impose Dirichlet boundary conditions, $u(-L)=u_{a}, u(L)=u_{b}$ and use the centered finite difference approximation at every point in the mesh. We arrive at the four equations: \\begin{align*} \\left(d_{x x} u\\right)_{1} \u0026amp;=\\frac{1}{\\Delta x^{2}}\\left(u_{a}-2 u_{1}+u_{2}\\right) \\qquad \\left(d_{x x} u\\right)_{2} =\\frac{1}{\\Delta x^{2}}\\left(u_{1}-2 u_{2}+u_{3}\\right) \\\\\\\\\\\\ \\left(d_{x x} u\\right)_{3} \u0026amp;=\\frac{1}{\\Delta x^{2}}\\left(u_{2}-2 u_{3}+u_{4}\\right) \\qquad \\left(d_{x x} u\\right)_{4} =\\frac{1}{\\Delta x^{2}}\\left(u_{3}-2 u_{4}+u_{b}\\right) \\end{align*} Introducing \\begin{align*} \\vec{u}=\\left( \\begin{array}{c} \\psi_{1} \\\\\\ \\psi_{2} \\\\\\ \\psi_{3} \\\\\\ \\psi_{4} \\end{array} \\right) \\quad (\\overrightarrow{b c})=\\frac{1}{\\Delta x^{2}} \\left( \\begin{array}{c} \\psi_{a} \\\\\\ 0 \\\\\\ 0 \\\\\\ \\psi_{b} \\end{array} \\right) \\quad A=\\frac{1}{\\Delta x^{2}} \\left( \\begin{array}{rrrr} -2 \u0026amp; 1 \u0026amp; \u0026amp; \\\\\\ 1 \u0026amp; -2 \u0026amp; 1 \u0026amp; \\\\\\ \u0026amp; 1 \u0026amp; -2 \u0026amp; 1 \\\\\\ \u0026amp; \u0026amp; 1 \u0026amp; -2 \\end{array} \\right) \\end{align*} we can rewrite in matrix form as \\begin{align*} \\frac{d^2 \\psi}{dx^2} =\\frac{1}{\\Delta x^{2}}D= A \\vec{\\psi}+(\\overrightarrow{b c}) \\end{align*}\nPeriodic boundary conditions $\\color{red}{\\text{This subsection has to tested and worked out. First try did not work.}}$\nSuppose we have $M=8$ points on a linear periodic mesh, â€¦","date":1530144000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530144000,"objectID":"d7188ac69d21942cfe546598244a73d7","permalink":"https://4tini.github.io/luca4tini.github.io/post/eigenfunctions/","publishdate":"2018-06-28T00:00:00Z","relpermalink":"/luca4tini.github.io/post/eigenfunctions/","section":"post","summary":"The eigenfunctions of the time independent SchrÃ¶dinger equation are numerically computed by discretising with the finite difference method and using exact diagonalisation of sparse matrices.","tags":null,"title":"Eigenfunctions of the time independent Schrodinger equation","type":"post"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"e8f8d235e8e7f2efd912bfe865363fc3","permalink":"https://4tini.github.io/luca4tini.github.io/project/example/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/luca4tini.github.io/project/example/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Example Project","type":"project"}]